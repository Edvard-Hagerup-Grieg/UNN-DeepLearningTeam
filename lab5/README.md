# Лабораторная работа №5
# Применение переноса обучения для решения задачи,поставленной во второй лабораторной работе

+ [Входные данные](#Format_input)
+ [Описание программной реализации](#Description)
+ [Архитектуры нейронных сетей](#NN_architecture)
+ [Результаты экспериментов](#Results)


## <a name="Format_input"></a>	Входные данные
Из-за особенностей используемой архитектуры модели, нормированные изображения 28x28 пикселей расширялись до 32x32 пикселей 
путем добавления пустых пикселей по краям изображения.


## <a name="NN_architecture"></a>	Используемая архитектура
В качестве архитектуры для переноса обучения использовался MobileNet, так как данная архитектура имеет сравнительно
 небольшое количество параметров, поэтому на малом количестве данных меньше вероятность переобучения.
  Эксперименты проводились с использованием MobileNet со случайно сгенерированными весами, а также, с использованием весов 
   после обучения сети на ImageNet из предположения, что низкоуровневые признаки оттуда будут совпадать с 
   признаками используемого набора данных.  


Были использованы 3 различных подхода к переносу обучения: 
1) Использовалась только архитектура сети со случайными весами (обучались все веса)
2) Использовалась архитектура сети, предобученная на ImageNet (обучались все веса)
3) Использовалась архитектура сети, предобученная на ImageNet (обучались только веса последних слоёв)

## <a name="Description"></a>	Описание программной реализации
[dataset.py]() содержит методы для обработки входных данных:

+ load_dataset() загружает набор данных, нормирует расширяет x и приводит y к one-hot кодированию

[models.py]() содержит методы для создания моделей:

+ load_mobilenet_model() загружает модель архитектуры [MobileNet version 2]() при помощи модуля Application библиотеки Keras. 
Архитектура модифицируется для решения текущей задачи классификации, путем добавления в конце полносвязного слоя с 
количеством нейронов равным количеству классов и функцией активации softmax. Для выбора варианта переноса знаний 
варьируются значения ргументов weights и trainable, определяюих начальную инициализацию весов и обучаемые слои, 
соответственно. Так, для обучения модели, предобученной на данных imagenet, следует установить weights='imagenet' 
(по умолчанию установлено weights=None, что соответствует случайной инициализации весов). Аргумент trainable определяет 
будут ли обучаться все слои модели (trainable=True) или только последний полносвязный слой (trainable=False)

[experiments.py]() содержит методы для проведения экспериментов на моделях:

+ save_history_img() сохраняет график обучения
+ train_mobilenet_model() обучает модель и возвращает значение точности на тестовом наборе данных

## <a name="Results"></a>	Результаты экспериментов
Обучение отанавливается при достижении 150 эпох или если в течении 5 эпох подряд ошибка на валидационном множестве 
не изменяется.

| Метод переноса обучения | Время обучения, эпохи | Качество решения, точность|
|:----------------:|:---------------------------:|:----------------------:|
| 1. Только архитектура| 25 | 0.8014 |
| 2. Предобучение на ImageNet, все веса  | 27 | 0.8486 |
| 3. Предобучение на ImageNet, последний слой | 150 | 0.1355 |

По результатам можно видеть, что использование предобученной сети улучшает точность сети по сравнению с использованием
случайных весов, также можно видеть, что обучение только последнего слоя отрицательно сказывается на точности.