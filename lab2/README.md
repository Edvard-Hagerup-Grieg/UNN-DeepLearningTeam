# Лабораторная работа №2
# Разработка полностью связанных нейронных сетей

+ [Входные данные](#Format_input)
+ [Архитектуры нейронных сетей](#NN_architecture)
+ [Результаты экспериментов](#Results)


## <a name="Format_input"></a>	Входные данные
Загрузка и предобработка данных реализована в файле [dataset.py](https://github.com/Edvard-Hagerup-Grieg/UNN-DeepLearningTeam/blob/report_lab2/lab2/dataset.py).


Для использования в качестве входного сигнала описанных ниже нейронных сетей, нормированные изображений 28x28 пикселей представляются в виде вектора длины 784.


## <a name="NN_architecture"></a>	Архитектуры нейронных сетей
В качестве архитектур использовались модели с 1-3 полносвязными скрытыми слоями. Количество нейронов варьировалось от 64 до 512
в каждом слое, функции активации, используемые на скрытых слоях: relu, сигмоид и линейная. На выходном слое всегда использовалась функция 
softmax, так как классов 10.

Используемые архитектуры сетей:

| Количество слоёв | Количество нейронов в слоях | Функция активации слоёв|
|:----------------:|:---------------------------:|:----------------------:|
| 1 | 256 | relu |
| 1 | 512 | relu |
| 2 | 512, 256 | relu |
| 3 | 512, 256, 64 | relu |
| 1 | 256 | linear |
| 1 | 512 | linear |
| 2 | 512, 256 | linear |
| 3 | 512, 256, 64 | linear |
| 1 | 256 | sigmoid |
| 1 | 512 | sigmoid |
| 2 | 512, 256 | sigmoid |
| 3 | 512, 256, 64 | sigmoid |




## <a name="Results"></a>	Результаты экспериментов
